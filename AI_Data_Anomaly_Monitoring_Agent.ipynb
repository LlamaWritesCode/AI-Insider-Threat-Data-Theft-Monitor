{
  "cells": [
    {
      "metadata": {
        "id": "3p-J31yDVBxu"
      },
      "cell_type": "markdown",
      "source": [
        "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
        "# Agents Lab Notebook v1.0.0\n",
        "This notebook contains steps and code to demonstrate the use of agents\n",
        "configured in Agent Lab in watsonx.ai. It introduces Python API commands\n",
        "for authentication using API key and invoking a LangGraph agent with a watsonx chat model.\n",
        "\n",
        "**Note:** Notebook code generated using Agent Lab will execute successfully.\n",
        "If code is modified or reordered, there is no guarantee it will successfully execute.\n",
        "For details, see: <a href=\"/docs/content/wsj/analyze-data/fm-prompt-save.html?context=wx\" target=\"_blank\">Saving your work in Agent Lab as a notebook.</a>\n",
        "\n",
        "Some familiarity with Python is helpful. This notebook uses Python 3.11.\n",
        "\n",
        "## Notebook goals\n",
        "The learning goals of this notebook are:\n",
        "\n",
        "* Defining a Python function for obtaining credentials from the IBM Cloud personal API key\n",
        "* Creating an agent with a set of tools using a specified model and parameters\n",
        "* Invoking the agent to generate a response\n",
        "\n",
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph"
      ],
      "metadata": {
        "id": "JiVVxrRxVWfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LU89INsiVBx4"
      },
      "cell_type": "code",
      "source": [
        "# import dependencies\n",
        "from langchain_ibm import ChatWatsonx\n",
        "from ibm_watsonx_ai import APIClient\n",
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from ibm_watsonx_ai.foundation_models.utils import Tool, Toolkit\n",
        "import json\n",
        "import requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_0v2otLhVBx6"
      },
      "cell_type": "markdown",
      "source": [
        "## watsonx API connection\n",
        "This cell defines the credentials required to work with watsonx API for Foundation\n",
        "Model inferencing.\n",
        "\n",
        "**Action:** Provide the IBM Cloud personal API key. For details, see\n",
        "<a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\">documentation</a>.\n"
      ]
    },
    {
      "metadata": {
        "id": "NQoJ5_lbVBx7"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "def get_credentials():\n",
        "\treturn {\n",
        "\t\t\"url\" : \"https://us-south.ml.cloud.ibm.com\",\n",
        "\t\t\"apikey\" : getpass.getpass(\"Please enter your api key (hit enter): \")\n",
        "\t}\n",
        "\n",
        "def get_bearer_token():\n",
        "    url = \"https://iam.cloud.ibm.com/identity/token\"\n",
        "    headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
        "    data = f\"grant_type=urn:ibm:params:oauth:grant-type:apikey&apikey={credentials['apikey']}\"\n",
        "\n",
        "    response = requests.post(url, headers=headers, data=data)\n",
        "    return response.json().get(\"access_token\")\n",
        "\n",
        "credentials = get_credentials()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DVw1SdzdVByD"
      },
      "cell_type": "markdown",
      "source": [
        "# Using the agent\n",
        "These cells demonstrate how to create and invoke the agent\n",
        "with the selected models, tools, and parameters.\n",
        "\n",
        "## Defining the model id\n",
        "We need to specify model id that will be used for inferencing:"
      ]
    },
    {
      "metadata": {
        "id": "CwQta9cEVByE"
      },
      "cell_type": "code",
      "source": [
        "model_id = \"ibm/granite-3-3-8b-instruct\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dnb_7P6uVByF"
      },
      "cell_type": "markdown",
      "source": [
        "## Defining the model parameters\n",
        "We need to provide a set of model parameters that will influence the\n",
        "result:"
      ]
    },
    {
      "metadata": {
        "id": "vLdXY6oaVByF"
      },
      "cell_type": "code",
      "source": [
        "parameters = {\n",
        "    \"frequency_penalty\": 0,\n",
        "    \"max_tokens\": 2000,\n",
        "    \"presence_penalty\": 0,\n",
        "    \"temperature\": 0,\n",
        "    \"top_p\": 1\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LFpy8EhtVByH"
      },
      "cell_type": "markdown",
      "source": [
        "## Defining the project id or space id\n",
        "The API requires project id or space id that provides the context for the call. We will obtain\n",
        "the id from the project or space in which this notebook runs:"
      ]
    },
    {
      "metadata": {
        "id": "IZFMsn2eVByI"
      },
      "cell_type": "code",
      "source": [
        "# project_id = os.getenv(\"1388b14c-0ca5-4d3d-b5b4-57b2b3b027d1\")\n",
        "# space_id = os.getenv(\"SPACE_ID\")\n",
        "\n",
        "# Prompt the user to enter either project_id or space_id\n",
        "project_or_space_id = input(\"Please enter your watsonx.ai Project ID or Space ID: \")\n",
        "\n",
        "# Assuming the user provides one, assign it to the relevant variable.\n",
        "# You might need to adjust this logic based on whether you are using a project or a space.\n",
        "# For simplicity, we'll assume it's a project ID for now.\n",
        "project_id = project_or_space_id\n",
        "space_id = None # Set space_id to None if you are using project_id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "23rFsBAiVByJ"
      },
      "cell_type": "markdown",
      "source": [
        "## Creating the agent\n",
        "We need to create the agent using the properties we defined so far:"
      ]
    },
    {
      "metadata": {
        "id": "PlWHwpyLVByJ"
      },
      "cell_type": "code",
      "source": [
        "client = APIClient(credentials=credentials, project_id=project_id, space_id=space_id)\n",
        "\n",
        "# Create the chat model\n",
        "def create_chat_model():\n",
        "    chat_model = ChatWatsonx(\n",
        "        model_id=model_id,\n",
        "        url=credentials[\"url\"],\n",
        "        space_id=space_id,\n",
        "        project_id=project_id,\n",
        "        params=parameters,\n",
        "        watsonx_client=client,\n",
        "    )\n",
        "    return chat_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "laGMik5YVByK"
      },
      "cell_type": "code",
      "source": [
        "from ibm_watsonx_ai.deployments import RuntimeContext\n",
        "\n",
        "context = RuntimeContext(api_client=client)\n",
        "\n",
        "\n",
        "vector_index_id = \"d7594ea9-78d6-4cd0-abdd-5ca6736d152f\"\n",
        "\n",
        "def create_rag_tool(vector_index_id, api_client):\n",
        "    config = {\n",
        "        \"vectorIndexId\": vector_index_id,\n",
        "        \"projectId\": project_id # Ensure project_id is used here\n",
        "    }\n",
        "\n",
        "    tool_description = \"Search information in documents to provide context to a user query. Useful when asked to ground the answer in specific knowledge about Anomalies log\"\n",
        "\n",
        "    return create_utility_agent_tool(\"RAGQuery\", config, api_client, tool_description=tool_description)\n",
        "\n",
        "\n",
        "\n",
        "def create_utility_agent_tool(tool_name, params, api_client, **kwargs):\n",
        "    from langchain_core.tools import StructuredTool\n",
        "    utility_agent_tool = Toolkit(\n",
        "        api_client=api_client\n",
        "    ).get_tool(tool_name)\n",
        "\n",
        "    tool_description = utility_agent_tool.get(\"description\")\n",
        "\n",
        "    if (kwargs.get(\"tool_description\")):\n",
        "        tool_description = kwargs.get(\"tool_description\")\n",
        "    elif (utility_agent_tool.get(\"agent_description\")):\n",
        "        tool_description = utility_agent_tool.get(\"agent_description\")\n",
        "\n",
        "    tool_schema = utility_agent_tool.get(\"input_schema\")\n",
        "    if (tool_schema == None):\n",
        "        tool_schema = {\n",
        "            \"type\": \"object\",\n",
        "            \"additionalProperties\": False,\n",
        "            \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
        "            \"properties\": {\n",
        "                \"input\": {\n",
        "                    \"description\": \"input for the tool\",\n",
        "                    \"type\": \"string\"\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def run_tool(**tool_input):\n",
        "        query = tool_input\n",
        "        if (utility_agent_tool.get(\"input_schema\") == None):\n",
        "            query = tool_input.get(\"input\")\n",
        "\n",
        "        results = utility_agent_tool.run(\n",
        "            input=query,\n",
        "            config=params\n",
        "        )\n",
        "\n",
        "        return results.get(\"output\")\n",
        "\n",
        "    return StructuredTool(\n",
        "        name=tool_name,\n",
        "        description = tool_description,\n",
        "        func=run_tool,\n",
        "        args_schema=tool_schema\n",
        "    )\n",
        "\n",
        "\n",
        "def create_custom_tool(tool_name, tool_description, tool_code, tool_schema, tool_params):\n",
        "    from langchain_core.tools import StructuredTool\n",
        "    import ast\n",
        "\n",
        "    def call_tool(**kwargs):\n",
        "        tree = ast.parse(tool_code, mode=\"exec\")\n",
        "        custom_tool_functions = [ x for x in tree.body if isinstance(x, ast.FunctionDef) ]\n",
        "        function_name = custom_tool_functions[0].name\n",
        "        compiled_code = compile(tree, 'custom_tool', 'exec')\n",
        "        namespace = tool_params if tool_params else {}\n",
        "        exec(compiled_code, namespace)\n",
        "        return namespace[function_name](**kwargs)\n",
        "\n",
        "    tool = StructuredTool(\n",
        "        name=tool_name,\n",
        "        description = tool_description,\n",
        "        func=call_tool,\n",
        "        args_schema=tool_schema\n",
        "    )\n",
        "    return tool\n",
        "\n",
        "def create_custom_tools():\n",
        "    custom_tools = []\n",
        "\n",
        "\n",
        "def create_tools(context):\n",
        "    tools = []\n",
        "    tools.append(create_rag_tool(vector_index_id, client))\n",
        "\n",
        "\n",
        "    return tools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "99ZsLnlPVByL"
      },
      "cell_type": "code",
      "source": [
        "def create_agent(context):\n",
        "    # Initialize the agent\n",
        "    chat_model = create_chat_model()\n",
        "    tools = create_tools(context)\n",
        "\n",
        "    memory = MemorySaver()\n",
        "    instructions = \"\"\"# Notes\n",
        "- When a tool is required to answer the user's query, respond only with <|tool_call|> followed by a JSON list of tools used.\n",
        "- If a tool does not exist in the provided list of tools, notify the user that you do not have the ability to fulfill the request.\n",
        "# AI Insider Threat & Data Theft Monitor Agent Instructions (Strict Single-Log Processing with Timestamp Separation and No Output for Low Risk)\n",
        "\n",
        "You are an AI security monitoring agent responsible for reviewing system logs and generating incident reports.\n",
        "\n",
        "## 1. Objectives\n",
        "- Process **each log line separately and independently**.\n",
        "- For each log line:\n",
        "  - Decide whether it is anomalous.\n",
        "  - If it is anomalous, assess the risk level.\n",
        "  - If the risk level is **Medium or higher**, produce a single JSON incident report for that log line.\n",
        "  - If the risk level is **Low**, produce no output.\n",
        "  - If it is not anomalous, produce no output.\n",
        "- **Never merge or summarize multiple log lines.**\n",
        "- **Any change in timestamp indicates a new record that must always be treated independently.**\n",
        "\n",
        "## 2. Input Format\n",
        "Each log line has this structure:\n",
        "<Date>,<Time>,<Level>,<Source>,<EventID>,<Category>,<Description>\n",
        "\n",
        "Example:\n",
        "2025-06-28,23:09:08,Error,Security,36887,Suspicious Connection,A suspicious connection was made to IP: 203.0.113.45 by MLopez.\n",
        "\n",
        "## 3. Parsing Instructions\n",
        "For each line, extract:\n",
        "- date\n",
        "- time\n",
        "- level\n",
        "- event_id\n",
        "- category\n",
        "- description\n",
        "- username (from description if present)\n",
        "\n",
        "## 4. Anomaly Detection Criteria\n",
        "Mark a log line as anomalous if:\n",
        "- Level = \\\"Error\\\"\n",
        "- Category = \\\"Suspicious Connection\\\"\n",
        "- Category = \\\"Process Creation\\\" AND description contains \\\"suspicious process\\\"\n",
        "- EventID = 1102 (Audit Log Cleared)\n",
        "- EventID = 4740 (Account Lockout)\n",
        "\n",
        "## 5. Risk Level Assignment\n",
        "Assign a risk level:\n",
        "- Medium: Suspicious process creation or account lockout\n",
        "- High: Suspicious connection or audit log cleared\n",
        "- Critical: Clear evidence of severe compromise (e.e., mass data exfiltration)\n",
        "- Low: All other informational or minor events (for which you must output nothing)\n",
        "\n",
        "**Important:**\n",
        "- If the risk level is **Low**, output nothing.\n",
        "\n",
        "## 6. Output Rules\n",
        "**Important:**\n",
        "- For each anomalous log with risk level **Medium, High, or Critical**, output exactly one JSON object in this format:\n",
        "\n",
        "{\n",
        "  \\\"incident_id\\\": \\\"<unique identifier>\\\",\n",
        "  \\\"summary\\\": \\\"<clear human-readable description>\\\",\n",
        "  \\\"risk_level\\\": \\\"<Medium|High|Critical>\\\",\n",
        "  \\\"recommended_action\\\": \\\"<action>\\\",\n",
        "  \\\"details\\\": {\n",
        "    \\\"user\\\": \\\"<username if known>\\\",\n",
        "    \\\"event\\\": \\\"<the original log line>\\\",\n",
        "    \\\"timestamp\\\": \\\"<date and time>\\\"\n",
        "  }\n",
        "}\n",
        "\n",
        "- **Never output anything for logs with risk level Low.**\n",
        "- **Never reference any other log lines.**\n",
        "- **Never combine logs across timestamps.**\n",
        "\n",
        "## 7. Summarization Instructions\n",
        "The summary must:\n",
        "- Clearly state who was involved.\n",
        "- Describe the action.\n",
        "- Indicate when it occurred.\n",
        "- Include the risk level.\n",
        "- Provide the recommended action.\n",
        "\n",
        "## 8. Recommended Actions\n",
        "- Medium: Notify security team\n",
        "- High: Suspend user access and investigate\n",
        "- Critical: Lock workstation and escalate immediately\n",
        "\n",
        "## 9. Example Outputs\n",
        "\n",
        "**Input (High Risk):**\n",
        "2025-06-28,23:09:08,Error,Security,36887,Suspicious Connection,A suspicious connection was made to IP: 203.0.113.45 by MLopez.\n",
        "\n",
        "**Output:**\n",
        "{\n",
        "  \\\"incident_id\\\": \\\"INC20250628-0001\\\",\n",
        "  \\\"summary\\\": \\\"On June 28, 2025 at 23:09:08, user 'MLopez' made a suspicious connection to IP 203.0.113.45. Risk Level: High. Recommended Action: Suspend user access and investigate.\\\",\n",
        "  \\\"risk_level\\\": \\\"High\\\",\n",
        "  \\\"recommended_action\\\": \\\"Suspend user access and investigate\\\",\n",
        "  \\\"details\\\": {\n",
        "    \\\"user\\\": \\\"MLopez\\\",\n",
        "    \\\"event\\\": \\\"2025-06-28,23:09:08,Error,Security,36887,Suspicious Connection,A suspicious connection was made to IP: 203.0.113.45 by MLopez.\\\",\n",
        "    \\\"timestamp\\\": \\\"2025-06-28 23:09:08\\\"\n",
        "  }\n",
        "}\n",
        "\n",
        "**Input (Low Risk):**\n",
        "2025-06-28,01:42:37,Information,Security,4624,Logon,A logon was successfully performed. User: Admin.\n",
        "\n",
        "**Output:**\n",
        "(no output)\n",
        "\n",
        "## 10. No Anomalies\n",
        "If the log is not anomalous, output nothing.\n",
        "\n",
        "## 11. Consistency\n",
        "- Every log line is processed independently.\n",
        "- Never combine logs.\n",
        "- Never reference other logs.\n",
        "- Never output anything for Low risk.\n",
        "- Only output one JSON per anomalous log with Medium or higher risk.\n",
        "\"\"\"\n",
        "\n",
        "    agent = create_react_agent(chat_model, tools=tools, checkpointer=memory, prompt=instructions)\n",
        "\n",
        "    return agent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rNeAr5gfVByM"
      },
      "cell_type": "code",
      "source": [
        "# Visualize the graph\n",
        "from IPython.display import Image, display\n",
        "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
        "\n",
        "Image(\n",
        "    create_agent(context).get_graph().draw_mermaid_png(\n",
        "        draw_method=MermaidDrawMethod.API,\n",
        "    )\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ax63c8zTVByO"
      },
      "cell_type": "markdown",
      "source": [
        "## Invoking the agent\n",
        "Let us now use the created agent, pair it with the input, and generate the response to your question:\n"
      ]
    },
    {
      "metadata": {
        "id": "v3a0A6HVVByP"
      },
      "cell_type": "code",
      "source": [
        "agent = create_agent(context)\n",
        "\n",
        "def convert_messages(messages):\n",
        "    converted_messages = []\n",
        "    for message in messages:\n",
        "        if (message[\"role\"] == \"user\"):\n",
        "            converted_messages.append(HumanMessage(content=message[\"content\"]))\n",
        "        elif (message[\"role\"] == \"assistant\"):\n",
        "            converted_messages.append(AIMessage(content=message[\"content\"]))\n",
        "    return converted_messages\n",
        "\n",
        "question = input(\"Question: \")\n",
        "\n",
        "messages = [{\n",
        "    \"role\": \"user\",\n",
        "    \"content\": question\n",
        "}]\n",
        "\n",
        "generated_response = agent.invoke(\n",
        "    { \"messages\": convert_messages(messages) },\n",
        "    { \"configurable\": { \"thread_id\": \"42\" } }\n",
        ")\n",
        "\n",
        "print_full_response = False\n",
        "\n",
        "if (print_full_response):\n",
        "    print(generated_response)\n",
        "else:\n",
        "    result = generated_response[\"messages\"][-1].content\n",
        "    print(f\"Agent: {result}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6B48pCJyVByQ"
      },
      "cell_type": "markdown",
      "source": [
        "# Next steps\n",
        "You successfully completed this notebook! You learned how to use\n",
        "watsonx.ai inferencing SDK to generate response from the foundation model\n",
        "based on the provided input, model id and model parameters. Check out the\n",
        "official watsonx.ai site for more samples, tutorials, documentation, how-tos, and blog posts.\n",
        "\n",
        "<a id=\"copyrights\"></a>\n",
        "### Copyrights\n",
        "\n",
        "Licensed Materials - Copyright © 2024 IBM. This notebook and its source code are released under the terms of the ILAN License.\n",
        "Use, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n",
        "\n",
        "**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs (or equivalent) and License Information document for watsonx.ai Auto-generated Notebook (License Terms), such agreements located in the link below. Specifically, the Source Components and Sample Materials clause included in the License Information document for watsonx.ai Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n",
        "\n",
        "By downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"https://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BYC7LF\" target=\"_blank\">License Terms</a>  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d68ed736"
      },
      "source": [
        "import inspect\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "# Get the signature of the create_react_agent function\n",
        "signature = inspect.signature(create_react_agent)\n",
        "\n",
        "# Print the parameters the function accepts\n",
        "print(signature.parameters)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.10",
      "language": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}